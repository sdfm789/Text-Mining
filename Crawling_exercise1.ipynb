{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링1 - Static Crawling\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. urllib\n",
    "- 파이썬은 웹 사이트에 있는 데이터를 추출하기 위해 urllib 라이브러리 사용  \n",
    "- 이를 이용해 HTTP 또는 FTP를 사용해 데이터 다운로드 가능  \n",
    "- urllib은 URL을 다루는 모듈을 모아 놓은 패키지  \n",
    "- urllib.request 모듈은 웹 사이트에 있는 데이터에 접근하는 기능 제공, 또한 인증, 리다렉트, 쿠키처럼 인터넷을 이용한 다양한 요청과 처리가 가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request # 라이브러리 읽어들이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. urllib.request를 이용한 다운로드\n",
    "- urllib.request 모듈에 있는 urlretrieve() 함수 이용  \n",
    "- 다음의 코드는 PNG 파일을 test.png 라는 이름의 파일로 저장하는 예제임  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 읽어들이기\n",
    "from urllib import request\n",
    "\n",
    "url=\"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename=\"test.png\"\n",
    "\n",
    "request.urlretrieve(url, savename)\n",
    "print(\"저장되었습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. urlopen으로 파일에 저장하는 방법\n",
    "- request.urlopen()은 메모리에 데이터를 올린 후 파일에 저장하게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다..\n"
     ]
    }
   ],
   "source": [
    "# URL과 저장경로 지정 후 다운로드\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test1.png\"\n",
    "mem = request.urlopen(url).read()\n",
    "\n",
    "#파일로 저장하기, wb는 쓰기와 바이너리모드\n",
    "with open(savename, mode=\"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"저장되었습니다..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. API 사용하기\n",
    "### 클라이언트 접속 정보 출력 (기본)\n",
    "- API는 사용자의 요청에 따라 정보를 반환하는 프로그램  \n",
    "- IP 주소, UserAgent 등 클라이언트 접속정보 출력하는 \"IP 확인 API\" 접근해서 정보를 추출하는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ip]\n",
      "API_URI=http://api.aoikujira.com/ip/get.php\n",
      "REMOTE_ADDR=125.130.134.149\n",
      "REMOTE_HOST=125.130.134.149\n",
      "REMOTE_PORT=43998\n",
      "HTTP_HOST=api.aoikujira.com\n",
      "HTTP_USER_AGENT=Python-urllib/3.8\n",
      "HTTP_ACCEPT_LANGUAGE=\n",
      "HTTP_ACCEPT_CHARSET=\n",
      "SERVER_PORT=80\n",
      "FORMAT=ini\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 읽기\n",
    "url=\"http://api.aoikujira.com/ip/ini\"\n",
    "res=request.urlopen(url)\n",
    "data=res.read()\n",
    "\n",
    "#바이너리를 문자열로 변환하기\n",
    "text=data.decode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BeautifulSoup\n",
    "- 스크레이핑(Scraping or Crawling)이란 웹 사이트에서 데이터를 추출하고, 원하는 정보를 추출하는 것을 의미  \n",
    "- BeautifulSoup란 파이썬으로 스크레이핑할 때 사용되는 라이브러리로서 HTML/XML에서 정보를 추출할 수 있도록 도와줌. 그러나 다운로드 기능은 없음.  \n",
    "- 파이썬 라이브러리는 pip 명령어를 이용해 설치 가능. Python Package Index(PyPI)에 있는 패키지 명령어를 한줄로 설치 가능  \n",
    "    - URL (http://pypi.python.org/pypi)  \n",
    "```python\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "- 예제 HTML\n",
    "```python\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import 및 예제 HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #라이브러리 읽어들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 기본 사용\n",
    "- 다음은 Beautifulsoup를 이용하여 웹사이트로부터 HTML을 가져와 문자열로 만들어 이용하는 예제임  \n",
    "- h1 태그를 접근하기 위해 html-body-h1 구조를 사용하여 soup.html.body.h1 이런식으로 이용하게 됨.  \n",
    "- p 태그는 두개가 있어 soup.html.body.p 한 후 next_sibling을 두번 이용하여 다음 p를 추출. 한번만 하면 그 다음 공백이 추출됨.  \n",
    "- HTML 태그가 복잡한 경우 이런 방식으로 계속 진행하기는 적합하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HTML 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 원하는 부분 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 요소의 글자 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 스크레이핑이란?\n",
      "p  = 웹 페이지를 분석하는 것\n",
      "p  = 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "print(f\"h1 = {h1.string}\")\n",
    "print(f\"p  = {p1.string}\")\n",
    "print(f\"p  = {p2.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 요소를 찾는 method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 element 추출: find()  \n",
    "BeautifulSoup는 루트부터 하나하나 요소를 찾는 방법 말고도 find()라는 메소드를 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) find() 메서드로 원하는 부분 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>스크레이핑이란?</h1>\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(\"h1\")\n",
    "body  = soup.find(\"p\")\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2) 텍스트 부분 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = 스크레이핑이란?\n",
      "#body = 웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "print(f\"#title = {title.string}\" )\n",
    "print(f\"#body = {body.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 복수 elements 추출: find_all()\n",
    "여러개의 태그를 한번에 추출하고자 할때 사용함. 다음의 예제에서는 여러개의 태그를 추출하는 법을 보여주고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) find_all() 메서드로 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://www.naver.com\">naver</a>, <a href=\"http://www.daum.net\">daum</a>] 2\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all(\"a\")\n",
    "print(links, len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2) 링크 목록 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "for a in links:\n",
    "    href = a.attrs['href'] # href의 속성에 있는 속성값을 추출\n",
    "    text = a.string \n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Css Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Css Selector란, 웹상의 요소에 css를 적용하기 위한 문법으로, 즉 요소를 선택하기 위한 패턴입니다. <br/><br/>\n",
    "출처: https://www.w3schools.com/cssref/css_selectors.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 간단하게 태그를 사용하여 데이터를 추출하는 방법에 대해서 살펴보았습니다.  \n",
    "하지만 복잡하게 구조화된 웹 사이트에서 자신이 원하는 데이터를 가져오기 위해서는 Css Selector에 대한 이해가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서식|설명\n",
    "---|---|\n",
    "* |\t모든 요소를 선택\n",
    "<요소 이름>|요소 이름을 기반으로 선택\n",
    ".<클래스 이름>|클래스 이름을 기반으로 선택\n",
    "#<id 이름>|id 속성을 기반으로 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup에서 Css Selector 사용하기  \n",
    "BeautifulSoup에서는 Css Selector로 값을 가져올 수 있도록 find와는 다른 다음과 같은 메서드를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메서드|설명\n",
    "------|---------\n",
    "soup.select_one(선택자)|CSS 선택자로 요소 하나를 추출합니다.\n",
    "soup.select(선택자)|CSS 선택자로 요소 여러 개를 리스트를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 \n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 부분을 CSS 쿼리로 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 위키북스 도서\n",
      "li = 유니티 게임 이펙트 입문\n",
      "li = 스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "li = 모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "# 타이틀 부분 추출하기 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(f\"h1 = {h1}\")\n",
    "\n",
    "# 목록 부분 추출하기 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "  print(f\"li = {li.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 활용 예제\n",
    "앞서 배운 urllib과 BeautifulSoup를 조합하면, 웹스크레이핑 및 API 요청 작업을 쉽게 수행하실 수 있습니다.  \n",
    "1. URL을 이용하여 웹으로부터 html을 읽어들임 (urllib)  \n",
    "2. html 분석 및 원하는 데이터를 추출 (BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 네이버 금융 - 환율 정보\n",
    "- 다양한 금융 정보가 공개돼 있는 \"네이버 금융\"에서 원/달러 환율 정보를 추출해보자!  \n",
    "- 네이버 금융의 시장 지표 페이지 https://finance.naver.com/marketindex/  \n",
    "- 다음은 원/달러 환율 정보를 추출하는 프로그램임  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) HTML 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HTML 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 원하는 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/krw = 1,175.00\n"
     ]
    }
   ],
   "source": [
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw =\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 기상청 RSS\n",
    "- 기상청 RSS에서 특정 내용을 추출하는 예제  \n",
    "- 기상청 RSS에서 XML 데이터를 추출하고 XML 내용을 출력  \n",
    "- 기상청의 RSS 서비스에 지역 번호를 지정하여 데이터 요청해보기 http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp  \n",
    "    - 참고: 기상청 RSS http://www.kma.go.kr/weather/lifenindustry/service_rss.jsp  \n",
    "    \n",
    "매개변수|의미\n",
    "--------|------|\n",
    "stnid|기상정보를 알고 싶은 지역을 지정\n",
    "\n",
    "- 지역번호는 다음과 같음\n",
    "\n",
    "지역|지역번호|지역|지역번호\n",
    "----|-----|-----|-------|\n",
    "전국|108|전라북도|146\n",
    "서울/경기도|109|전라남도|156\n",
    "강원도|105|경상북도|143\n",
    "충청북도|131|경상남도|159\n",
    "충청남도|133|제주특별자치도|184\n",
    "\n",
    "- 파이썬으로 요청 전용 매개변수를 만들 때는 urllib.parse 모듈의 urlencode() 함수를 사용해 매개변수를 URL로 인코딩한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) HTML 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=109\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "\n",
    "#매개변수를 URL로 인코딩\n",
    "values = {\n",
    "    'stnId':'109'\n",
    "}\n",
    "\n",
    "params=parse.urlencode(values)\n",
    "url += \"?\"+params # URL에 매개변수 추가\n",
    "print(\"url=\", url)\n",
    "\n",
    "res = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HTML 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 원하는 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울,경기도 육상중기예보\n",
      "○ (강수) 10월 2일(금)에는 비가 내리겠습니다.<br />○ (기온) 이번 예보기간 낮 기온은 19~25도로 오늘(27일, 24~27도)보다 낮겠고, 아침 기온은 6~17도로 선선하겠습니다.<br />          특히, 내륙을 중심으로 낮과 밤의 기온차가 10도 내외로 크겠습니다.<br />○ (해상) 서해중부해상의 물결은 0.5~2.0m로 일겠습니다.\n"
     ]
    }
   ],
   "source": [
    "header = soup.find(\"header\")\n",
    "\n",
    "title = header.find(\"title\").text\n",
    "wf = header.find(\"wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- css selector 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "title = soup.select_one(\"header > title\").text\n",
    "wf = header.select_one(\"header wf\").text\n",
    "print(title)\n",
    "print(wf)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. 윤동주 작가의 작품 목록\n",
    "- 위키문헌 (https://ko.wikisource.org/wiki) 에 공개되어 있는 윤동주의 작품목록을 가져오기  \n",
    "- 윤동주 위키 (https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC)  \n",
    "- 하늘과 바람과 시 부분을 선택한 후 오른쪽 마우스 이용해 copy selector로 카피하면 다음의 CSS 선택자가 카피됨  \n",
    "    - #mw-content-text > div > ul:nth-child(6) > li > b > a  \n",
    "- nth-child(n) 은 n 번째 요소를 의미 즉 6번째 요소를 의미, #mw-content-text 내부에 있는 url 태그는 모두 작품과 관련된 태그. - 따라서 따로 구분할 필요는 없으며 생략해도 됨. BeautifulSoup는 nth-child 지원하지 않음  \n",
    "    - Recall PR7 Problem1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 하늘과 바람과 별과 시\n",
      "- 증보판\n",
      "- 서시\n",
      "- 자화상\n",
      "- 소년\n",
      "- 눈 오는 지도\n",
      "- 돌아와 보는 밤\n",
      "- 병원\n",
      "- 새로운 길\n",
      "- 간판 없는 거리\n",
      "- 태초의 아침\n",
      "- 또 태초의 아침\n",
      "- 새벽이 올 때까지\n",
      "- 무서운 시간\n",
      "- 십자가\n",
      "- 바람이 불어\n",
      "- 슬픈 족속\n",
      "- 눈감고 간다\n",
      "- 또 다른 고향\n",
      "- 길\n",
      "- 별 헤는 밤\n",
      "- 흰 그림자\n",
      "- 사랑스런 추억\n",
      "- 흐르는 거리\n",
      "- 쉽게 씌어진 시\n",
      "- 봄\n",
      "- 참회록\n",
      "- 간(肝)\n",
      "- 위로\n",
      "- 팔복\n",
      "- 못자는밤\n",
      "- 달같이\n",
      "- 고추밭\n",
      "- 아우의 인상화\n",
      "- 사랑의 전당\n",
      "- 이적\n",
      "- 비오는 밤\n",
      "- 산골물\n",
      "- 유언\n",
      "- 창\n",
      "- 바다\n",
      "- 비로봉\n",
      "- 산협의 오후\n",
      "- 명상\n",
      "- 소낙비\n",
      "- 한난계\n",
      "- 풍경\n",
      "- 달밤\n",
      "- 장\n",
      "- 밤\n",
      "- 황혼이 바다가 되어\n",
      "- 아침\n",
      "- 빨래\n",
      "- 꿈은 깨어지고\n",
      "- 산림\n",
      "- 이런날\n",
      "- 산상\n",
      "- 양지쪽\n",
      "- 닭\n",
      "- 가슴 1\n",
      "- 가슴 2\n",
      "- 비둘기\n",
      "- 황혼\n",
      "- 남쪽 하늘\n",
      "- 창공\n",
      "- 거리에서\n",
      "- 삶과 죽음\n",
      "- 초한대\n",
      "- 산울림\n",
      "- 해바라기 얼굴\n",
      "- 귀뚜라미와 나와\n",
      "- 애기의 새벽\n",
      "- 햇빛·바람\n",
      "- 반디불\n",
      "- 둘 다\n",
      "- 거짓부리\n",
      "- 눈\n",
      "- 참새\n",
      "- 버선본\n",
      "- 편지\n",
      "- 봄\n",
      "- 무얼 먹구 사나\n",
      "- 굴뚝\n",
      "- 햇비\n",
      "- 빗자루\n",
      "- 기왓장 내외\n",
      "- 오줌싸개 지도\n",
      "- 병아리\n",
      "- 조개껍질\n",
      "- 겨울\n",
      "- 트루게네프의 언덕\n",
      "- 달을 쏘다\n",
      "- 별똥 떨어진 데\n",
      "- 화원에 꽃이 핀다\n",
      "- 종시\n"
     ]
    }
   ],
   "source": [
    "# 뒤의 인코딩 부분은 \"저자:윤동주\"라는 의미입니다.\n",
    "# 따로 입력하지 말고 위키 문헌 홈페이지에 들어간 뒤에 주소를 복사해서 사용하세요.\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# #mw-content-text 바로 아래에 있는 \n",
    "# ul 태그 바로 아래에 있는 -> li 태그 아래에 있는 -> a 태그를 모두 선택\n",
    "a_list = soup.select(\"#mw-content-text   ul > li  a\")\n",
    "for a in a_list:\n",
    "    name = a.string\n",
    "    print(f\"- {name}\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일반문제\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음 뉴스 헤드라인 \n",
    "배운 내용을 바탕으로 다음 뉴스(https://news.daum.com/) 에서 헤드라인 뉴스의 제목을 추출해보고자 합니다.\n",
    "\n",
    "> Q: 다음의 코드에 css selector를 추가하여 최신 기사의 헤드라인을 스크레이핑하는 코드를 완성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추석 연휴 문 닫는 묘역들..이른 성묘객 '북적'\n",
      "\n",
      "\t                            전국 곳곳 '미리 성묘객'..일부 인파 몰려 감염 우려도\n",
      "\t\t\t\t\t\t\t\n",
      "\n",
      "\t                            추석 연휴 문 닫는 묘지시설..이른 성묘 나선 추모객들\n",
      "\t\t\t\t\t\t\t\n",
      "\"성소수자, 길벗체처럼 명랑하게 살길\"\n",
      "\n",
      "\t                                '흑백논리'의 세상에 새긴 '무지개빛' 위로..'길벗체'는 이렇게 태어났다\n",
      "\t\t\t\t\t\t\t\t\n",
      "만취 차량, 포장마차 돌진..시민들 달려들어 잡았다\n",
      "\n",
      "\t                                생방송에 잡힌 '음주 뺑소니'..포장마차 덮쳐\n",
      "\t\t\t\t\t\t\t\t\n",
      "시민단체, 민경욱 고발..\"경찰청장에 '개떼 두목' 모욕\"\n",
      "\n",
      "\t                                시민단체 '경찰청장은 개떼두목' 지칭한 민경욱 고발..\"15만 경찰 모욕\"\n",
      "\t\t\t\t\t\t\t\t\n",
      "신규 확진자 이틀째 두 자릿수..\"연휴간 이동 자제, 불법집회엔 무관용\"\n",
      "\n",
      "\t                                신규 확진자 이틀째 두 자릿수..서울시, 거리두기 2단계 유지\n",
      "\t\t\t\t\t\t\t\t\n",
      "\n",
      "                        이낙연 시신 '화장' 표현에..野 \"北이 장사 지냈나\" 비판\n",
      "\t\t\t\t\t\n",
      "\n",
      "                        질병청 \"'상온 노출' 의심 백신 접종자들 건강 매일 확인 중\"\n",
      "\t\t\t\t\t\n",
      "\n",
      "                        '상온 노출' 독감 백신 접종 추정자 324명.. \"현재 이상반응 보고 없어\"\n",
      "\t\t\t\t\t\n",
      "\n",
      "                        \"대통령 어디 있나\"..국민의힘 청와대 앞 1인시위\n",
      "\t\t\t\t\t\n",
      "\n",
      "                        소득 많아도 '다문화' 이유로 주택특별공급.. 내국인 역차별\n",
      "\t\t\t\t\t\n",
      "일본 코로나 신규 확진 400명대로 줄어..도쿄도 144명\n",
      "자발적 '착한 임대'..코로나19 극복 상생의 길\n",
      "코로나19로 힘든 상인 여러분..\"월세 깎아달라\" 당당하게 말하세요\n",
      "\"조두순 재범 위험있다\"..법무부, 외출제한 등 검토\n",
      "조두순 감시할 유단자 6명 채용..엇갈린 시민 반응\n",
      "12월 출소 앞둔 조두순.. \"무술 유단자 6명 순찰시킨다\"는 안산시\n",
      "서울 오후 6시까지 확진자 16명 추가..누적 확진자 최소 5228명\n",
      "자가격리 권고 중 제주여행..연락두절에 보건당국 '화들짝'\n",
      "서울 확진자 16명 늘어..총 5228명 확진\n",
      "앵커의 눈\n",
      "완전 회복하려면 최소 수십년..\"빨리 복구 안하면 산사태\"\n",
      "가신이의 발자취\n",
      "\"분단없는 하늘에서 통일열사들과 '빗자루 무예' 펼치소서\"\n",
      "매경이 만난 사람\n",
      "농민들 돈 벌게 '유통개혁' 착수..쿠팡·마켓컬리와 경쟁할것\n",
      "방구석 연대기\n",
      "\"'코로나 비용' 청구서, '국가'로 반송해야 합니다\"\n",
      "인-잇\n",
      "세상을 뒤집은 반대자, R.I.P RBG\n",
      "\"내 잘못인 것 같아 죄책감\"..말바우시장 국밥집 주인의 눈물\n",
      "13년 만에 생긴 산부인과..'원정 출산' 안 해도 돼\n",
      "과학고는 매일 등교, 일반고는 온·오프 병행..교육격차 더 벌린 '학급당 학생 수'\n",
      "\"조두순 재범 위험있다\"..법무부, 외출제한 등 검토\n",
      "자가격리 권고 중 제주여행..연락두절에 보건당국 '화들짝'\n",
      "\"전국의 동네책방 모두 고사할 것\"\n",
      "생방송에 잡힌 '음주 뺑소니'..포장마차 덮쳐\n",
      "군복 입고 박박 기던  벨기에 공주.. '블루 베레' 썼다\n",
      "秋아들 \"휴가 승인 받아\".. 부대 관계자들 \"기억 없다\"\n",
      "군복 입고 박박 기던  벨기에 공주.. '블루 베레' 썼다\n",
      "\"조두순 재범 위험있다\"..법무부, 외출제한 등 검토\n",
      "조두순 감시할 유단자 6명 채용..엇갈린 시민 반응\n",
      "\n",
      "                                        군복 입고 박박 기던  벨기에 공주.. '블루 베레' 썼다\n",
      "                                    \n",
      "\n",
      "                                         \"총검술 문제있어?\" 이근 대위 국감증인 막는 여당\n",
      "                                    \n",
      "\n",
      "                                        생방송에 잡힌 '음주 뺑소니'..포장마차 덮쳐\n",
      "                                    \n",
      "\n",
      "                                        '사과' 이틀 만에 경고 메시지..북 발언에 담긴 의미는\n",
      "                                    \n",
      "\n",
      "                                        수돗물서 '뇌 먹는 아메바' 검출.. 美텍사스 도시에 재난선포\n",
      "                                    \n",
      "\n",
      "                                        13년 만에 생긴 산부인과..'원정 출산' 안 해도 돼\n",
      "                                    \n",
      "\n",
      "                                        세계적인 모델 기획사 전직 수장, 소속 모델 성폭행 혐의로 피소\n",
      "                                    \n",
      "\n",
      "                                         月24만원 건보료가 3만원으로..위장취업하는 노인들\n",
      "                                    \n",
      "\n",
      "                                        최대집 의협회장, 불신임 부결에 오히려 힘 실려..\"국시문제 해결할 것\"\n",
      "                                    \n",
      "\n",
      "                                        곽상도 \"노영민, 반포 아파트 판다더니..등기부엔 아직 보유 중\"\n",
      "                                    \n",
      "\n",
      "                                        \"조두순 재범 위험있다\"..법무부, 외출제한 등 검토\n",
      "                                    \n",
      "\n",
      "                                        자가격리 권고 중 제주여행..연락두절에 보건당국 '화들짝'\n",
      "                                    \n",
      "\n",
      "                                        과학고는 매일 등교, 일반고는 온·오프 병행..교육격차 더 벌린 '학급당 학생 수'\n",
      "                                    \n",
      "\n",
      "                                         \"퇴직 전 대량 전송\" 기밀 유출 의심 46명 더 포착\n",
      "                                    \n",
      "\n",
      "                                        질투가 화근..태국 결혼 축하연서 총격, 5명 사상\n",
      "                                    \n",
      "\n",
      "                                        \"내 잘못인 것 같아 죄책감\"..말바우시장 국밥집 주인의 눈물\n",
      "                                    \n",
      "\n",
      "                                        집주인 \"실거주\" 한마디에, 짐싸야 하는 세입자들\n",
      "                                    \n",
      "\n",
      "                                        학교에 갇힌 3천만 명..中 대학생들 \"봉쇄 해제해!\"\n",
      "                                    \n",
      "\n",
      "                                         秋아들 \"휴가 승인 받아\".. 부대 관계자들 \"기억 없다\"\n",
      "                                    \n",
      "\n",
      "                                         황교안 '만찬의 이유?'..참석자에게 들어보니\n",
      "                                    \n",
      "\n",
      "                                         완전 회복하려면 최소 수십년..\"빨리 복구 안하면 산사태\"\n",
      "                                    \n",
      "\n",
      "                                        시민단체 '경찰청장은 개떼두목' 지칭한 민경욱 고발..\"15만 경찰 모욕\"\n",
      "                                    \n",
      "\n",
      "                                        사방으로 뒤엉킨 유해.. 처참한 모습에 발굴단마저 눈감았다\n",
      "                                    \n",
      "\n",
      "                                        '광화문광장' 넓어지고 나무 그늘 생긴다\n",
      "                                    \n",
      "\n",
      "                                        \"전국의 동네책방 모두 고사할 것\"\n",
      "                                    \n",
      "\n",
      "                                        전세금 못올리게 된 집주인들 \"집수리 못해줘\"\n",
      "                                    \n",
      "\n",
      "                                         정치권-검찰-조선일보-사학, 끈끈한 커넥션\n",
      "                                    \n",
      "\n",
      "                                        코로나에도 '얼굴 없는 천사'는 왔습니다\n",
      "                                    \n",
      "\n",
      "                                        안철수 \"정부 코로나19 대응, 공은 가로채고 잘못은 남 탓\"\n",
      "                                    \n",
      "\n",
      "                                        尹 처가 고소인 판결문 보니..\"수익 절반 못받자 대출방해, 약정서 작성 협박\"\n",
      "                                    \n",
      "\n",
      "                                        \"전날까지 가족과 행복했는데\"..다케우치 유코, 8개월 아들 두고 왜 떠났나\n",
      "                                    \n",
      "\n",
      "                                        신화 전진♥3살 연하 승무원 오늘 결혼..김동완→인순이 축가 '축복' \n",
      "                                    \n",
      "\n",
      "                                        '뭉찬' 이만기 \"강호동 '깝죽거리지 마' 사건, 너무 열받았었다\"\n",
      "                                    \n",
      "\n",
      "                                        '당나귀귀' 현주엽 \"허재, 선수 시절 수표로 몇 백씩 줬다\"\n",
      "                                    \n",
      "\n",
      "                                        '동상이몽2' 장신영, 시부모 앞 ♥강경준 눈치 없는 행동에 본노의 '등짝 스매싱'\n",
      "                                    \n",
      "\n",
      "                                        '선녀들' 최수종 \"'태조 왕건' 4년간 촬영, 4박5일 지방서 잤다\"\n",
      "                                    \n",
      "\n",
      "                                        '당나귀 귀' 다니엘 헤니 \"2주 간 자가격리, 힘든 것보다 심심하더라\"\n",
      "                                    \n",
      "\n",
      "                                        日 톱배우 다케우치 유코, 오늘 자택서 사망..향년 40세\n",
      "                                    \n",
      "\n",
      "                                        \"여기가 쇼생크야\"..'오! 삼광빌라!' 진기주, 전인화와 가족들에 울분\n",
      "                                    \n",
      "\n",
      "                                        신화 김동완, 전진 결혼식 축가 불렀다..신화 우정 '포에버' \n",
      "                                    \n",
      "\n",
      "                                        전인화, 아들 지상 언급 \"슈퍼밴드 출연 진짜 몰랐다\"\n",
      "                                    \n",
      "\n",
      "                                        수영 측, '런 온' 스태프 코로나19 확진에 \"밀접접촉자 NO\"\n",
      "                                    \n",
      "\n",
      "                                        '집사부' 이승기, 설민석 등장에 당황 \"선물받은 안경 경매에 팔아\"\n",
      "                                    \n",
      "\n",
      "                                        전진 결혼, 승무원 예비신부와 오늘 웨딩마치\n",
      "                                    \n",
      "\n",
      "                                        '복면가왕' 흑마 정체는 심형래 \"개그 후배들에게 힘주고파\"\n",
      "                                    \n",
      "\n",
      "                                        '당나귀 귀' 200평 대저택 장동민조차 \"집 가기 싫다\" 탐낸 건축가 누구?\n",
      "                                    \n",
      "\n",
      "                                        '당나귀 귀' 임성빈, 송훈 셰프에 \"제주도 2호점 예산, 2억으로 충분\"\n",
      "                                    \n",
      "\n",
      "                                        '집사부일체' 설민석 \"코로나 위기를 기회로\"..타일러 환경위기 강의 \n",
      "                                    \n",
      "\n",
      "                                        전인화 \"김희애X조용원과 중앙대 3대 미인이었다\"\n",
      "                                    \n",
      "\n",
      "                                        '런닝맨' 하하, 유재석 연애사 폭로→에일리 男기죽인 이름표 뜯기 대활약 \n",
      "                                    \n",
      "\n",
      "                                        JTBC '런 온' 스태프 코로나 확진..임시완·신세경 격리\n",
      "                                    \n",
      "\n",
      "                                         '뭉쳐야 찬다' 홍성흔, \"김병현, 현역시절 말붙이기 힘든 선수\"\n",
      "                                    \n",
      "\n",
      "                                        '미우새' 제시→김종국에 ♥콜 \"얼굴·마인드 내 스타일, 정말 완벽한 남자\"\n",
      "                                    \n",
      "\n",
      "                                        '런닝맨' 강남, 여전한 이상화 사랑꾼 \"살 찐 이유? 결혼해서\"\n",
      "                                    \n",
      "\n",
      "                                        '당나귀 귀' 양치승, 다니엘 헤니에 영업→현주엽, 허재 투자 위해 고군분투\n",
      "                                    \n",
      "\n",
      "                                        '당나귀 귀' 양치승 \"코로나19로 헬스장 운영 어려워..홈쇼핑 출연\"\n",
      "                                    \n",
      "\n",
      "                                        신정환, 유튜브 채널 개설 후 셀프디스 \"이제 열 없다..10년 째 놀고있어\"\n",
      "                                    \n",
      "\n",
      "                                        '집사부' 타일러 \"환경오염, 지구 종말 예언..30년後 한국 침수→부산 반도될 것\" 충격 \n",
      "                                    \n",
      "\n",
      "                                        '당나귀귀' 장동민 \"임성빈 사무실, 원한다고 올 수 있는 곳 아냐\"\n",
      "                                    \n",
      "\n",
      "                                        '복면가왕' 부뚜막 고양이 新 가왕 등극, 숨은그림찾기 정체는 김정은 \n",
      "                                    \n",
      "\n",
      "                                         'SON, 5G 연속 선발'..토트넘, 뉴캐슬전 명단 발표\n",
      "                                    \n",
      "\n",
      "                                        \"10년 차 없는 PS 진출\" TOR, 105년 만의 기적 만들었다\n",
      "                                    \n",
      "\n",
      "                                        \"웃기는 일\".. 브루스 감독, 무리뉴 감독 비판에 일침\n",
      "                                    \n",
      "\n",
      "                                        'LAA PS 탈락' 마이크 트라웃 \"좌절감만 쌓이고 있다\"\n",
      "                                    \n",
      "\n",
      "                                        류현진 PS 2차전 등판도 괜찮다? 현지 언론 분석, 왜 그럴까\n",
      "                                    \n",
      "\n",
      "                                        EPL 득점왕의 평가, \"손흥민, 점점 발전해 톱 플레이어 됐다\"\n",
      "                                    \n",
      "\n",
      "                                         최강희의 상하이, 허난에 2-0 완승..2연승+6G 무패\n",
      "                                    \n",
      "\n",
      "                                         '단독 5위 사수' 두산, 키움과 DH 2경기 6-1 승\n",
      "                                    \n",
      "\n",
      "                                        김광현은 PS 무대에 설 수 있을까..28일, 시즌이 끝나야 한다\n",
      "                                    \n",
      "\n",
      "                                        김태진 연장 10회 끝내기 안타..KIA, 롯데에 2-1 설욕 '통산 2500승' \n",
      "                                    \n",
      "\n",
      "                                        레알 떠나온 베일 \"행복하지 않으면 좋은 경기 펼칠 수 없다\"\n",
      "                                    \n",
      "\n",
      "                                        \"김광현, 변칙적으로 PS 1선발 맡을수도\" 美 매체\n",
      "                                    \n",
      "\n",
      "                                         '충격 2연패' 샬케, 와그너 감독 전격 경질\n",
      "                                    \n",
      "\n",
      "                                        디 마리아 폭발했다!..\"대표팀 제외 왜? 나이 문제라면 메시도 안 뽑혀야\"\n",
      "                                    \n",
      "\n",
      "                                        안송이, 10개월 만에 팬텀 클래식서 통산 2승 달성..'처음이 어렵지 그 다음은 쉬워요'\n",
      "                                    \n",
      "\n",
      "                                        'KIA 2500승' 윌리엄스, \"양현종 10승 못해 아쉽다\" \n",
      "                                    \n",
      "\n",
      "                                        \"의지 부족한 아자르, 더 이상 면죄부 줄 수 없어\"..西전문가의 일침\n",
      "                                    \n",
      "\n",
      "                                        '0대6 완패' 김남일 감독 \"내 책임이다\"\n",
      "                                    \n",
      "\n",
      "                                        '생애 첫 끝내기' 김태진의 여유, \"팬들이 보셔야 했는데..\" \n",
      "                                    \n",
      "\n",
      "                                        류현진은 왜 하필, 정규시즌 마지막 등판에서 시즌 최다 100개 투구를 했을까\n",
      "                                    \n",
      "\n",
      "                                        '2경기 8골 관여' 손흥민-케인, BBC 전문가 \"뉴캐슬전도 기대\"\n",
      "                                    \n",
      "\n",
      "                                        아데산야 UFC 타이틀 방어..20연승 파죽지세\n",
      "                                    \n",
      "\n",
      "                                        \"토론토 가을 성적? 완벽 에이스 류현진이 짊어져야 한다\" 美 언론\n",
      "                                    \n",
      "\n",
      "                                         '일류첸코 해트트릭' 포항, '2명 퇴장' 광주에 5-3 승..3위 유지\n",
      "                                    \n",
      "\n",
      "                                        '홀대받고 저평가' 류현진, \"PS 16개팀 1선발 중 랭킹 9위\" 美매체 평가\n",
      "                                    \n",
      "\n",
      "                                         '홈런 기부 엔젤' 아델, 패배 원흉이 된 치명적 실수\n",
      "                                    \n",
      "\n",
      "                                        '배정대 9회 끝내기' KT, LG 꺾고 단독 3위..고우석이 무너졌다 \n",
      "                                    \n",
      "\n",
      "                                        무리뉴, 스트라이커 부족에 '좌절감' 점점 상승\n",
      "                                    \n",
      "\n",
      "                                        우드러프 108구 & 휠러 118구..PS 열망 에이스들 \"내일은 없다\"\n",
      "                                    \n",
      "\n",
      "                                        '이승기 결승포' 전북, 상주 1-0 꺾고 3연승-울산과 승점 동률 2위 \n",
      "                                    \n",
      "뉴스홈\n",
      "사회\n",
      "정치\n",
      "경제\n",
      "국제\n",
      "문화\n",
      "IT\n",
      "포토\n",
      "TV\n",
      "이슈\n",
      "언론사별 뉴스\n",
      "배열이력\n",
      "전체뉴스\n",
      "랭킹\n",
      "연재\n",
      "1boon\n"
     ]
    }
   ],
   "source": [
    "#네이버는 오류가 떠서 다음 뉴스로 진행하였다\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://news.daum.net/society#1\") #사회면을 가지고 왔다\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "data = soup.find_all('a', 'link_txt')\n",
    "\n",
    "for item in data:\n",
    "    print (item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시민의 소리 게시판\n",
    "다음은 서울시 대공원의 시민의 소리 게시판 입니다.  \n",
    "https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgList.do?pgno=1  \n",
    "해당 페이지에 나타난 게시글들의 제목을 수집하고자 합니다.  \n",
    "\n",
    "> Q: 다음의 코드에 css selector를 추가하여 해당 페이지에서 게시글의 제목을 스크레이핑하는 코드를 완성하시오. 또한 과제 제출시 하단의 추가 내용을 참고하여 수집한 데이터를 csv 형태로 저장하여 해당 csv 파일도 함께 제출하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['관리인 마스크', '어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청 ', '마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.', '공원 내 마스크 착용', '청춘핫도그 점장님과 직원분께 감사드립니다', '카드결제를 거부하는 매점을 신고합니다', '참얼굴만큼예쁘고맘씨좋은 여직원을 만나 고마워서 글을남깁니다.', '놀이동산에서 불쾌함을 겪었습니다', '서문 플래카드', '간만에 친절한 아가씨를 만났어요.(놀이동산)'] ['https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200917000010&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200902000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200826000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200825000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200818000009&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200816000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200813000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200813000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200730000004&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=JmEd7cUkk1DRzNRAetH0hUPBf9aQsTyQoIE06MAUvHMyOJxtV94YOMutyVp7h8pV.etisw1_servlet_user?qnaid=QNAS20200728000002&pgno=1']\n"
     ]
    }
   ],
   "source": [
    "url_head = \"https://www.sisul.or.kr\" #url 불러오기\n",
    "\n",
    "url_board = url_head + \"/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\"\n",
    "\n",
    "\n",
    "\n",
    "res = request.urlopen(url_board)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "titles = []\n",
    "links = []\n",
    "for a in soup.select(selector):\n",
    "    titles.append(a.text)\n",
    "    links.append(url_head + a.attrs[\"href\"])\n",
    "    \n",
    "print(titles, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 내용\n",
    "수집된 자료를 데이터프레임으로 만들어 csv로 저장하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>관리인 마스크</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>공원 내 마스크 착용</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>청춘핫도그 점장님과 직원분께 감사드립니다</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                             관리인 마스크   \n",
       "1         어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청    \n",
       "2  마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.   \n",
       "3                         공원 내 마스크 착용   \n",
       "4              청춘핫도그 점장님과 직원분께 감사드립니다   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "1  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "2  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "3  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "4  https://www.sisul.or.kr/open_content/childrenp...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "board_df = pd.DataFrame({\"title\": titles, \"link\": links})\n",
    "board_df.head() # 상위 다섯개만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_df.to_csv(\"board.csv\", index=False) #csv파일로 변환"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
